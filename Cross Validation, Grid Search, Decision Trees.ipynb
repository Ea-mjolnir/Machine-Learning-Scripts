{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - Cross Validation, Grid Search, Decision Trees\n",
    "\n",
    "**Note that this notebook was developed for an in-class exercise, where assistance and help is given in the classroom. We therefore provide most of the solutions, and on the other side, some parts might not be self-explanatory. Please check the documentation of scikit-learn in any case and check online resources to get further information, if the material we provided are not sufficient to understand everything. We hope you still get a lot out of this notebook in any case.**\n",
    "\n",
    "**This notebook also has some repetitions from previous notebooks using the census dataset. You can try to solve the given tasks yourself, or use the accompanying pdf-version to follow the solutions. Working through the notebook without help is, of course, more effective for practicing and learning the content.**\n",
    "\n",
    "A machine learning project includes the following stages:\n",
    "* data collection\n",
    "* exploratory data analysis - computing basic statistics, correlations, and visualizations in order to get insights into the data\n",
    "* data preparation:\n",
    "    * dealing with missing data\n",
    "    * transforming categorical features into numerical features: one-hot encoding\n",
    "    * data transformation - e.g. logarithmic transformations for features with skewed distributions\n",
    "    * training test splitting \n",
    "    * data scaling - all numerical features have similar order of magnitude    \n",
    "* model selection and training\n",
    "* model evaluation\n",
    "* model/hyperparameters fine-tuning\n",
    "\n",
    "In the framework of this exercise, you will practice:\n",
    "- more on model evaluation: ROC curve,\n",
    "- training a new classifier: Decision Trees\n",
    "- cross validation\n",
    "- hyperparameter selection with grid search\n",
    "\n",
    "The dataset for this project originates from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Census+Income). The dataset was donated by Ron Kohavi and Barry Becker, after being published in the article _\"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"_. You can find the article by Ron Kohavi [online](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf). The data we investigate here consists of small changes to the original dataset, such as removing the `'fnlwgt'` feature and records with missing or ill-formatted entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Import necessary Python libraries for solving this exercise: `numpy, pandas, sklearn, sklearn, matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the *census.csv* dataset consisting of income data from the census, classifying adults into those earning above ``$50k`` per year vs. those earning below. Note that the last column from this dataset, `'income'`, will be our target label (whether an individual makes more than, or at most, $50,000 annually). All other columns are features about each individual in the census database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/coursematerial/GIS/GeoDataScience/census.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "data_dir = str(Path.home()) + r'/coursematerial/GIS/GeoDataScience'\n",
    "\n",
    "filepath = os.path.join(data_dir, r'census.csv')\n",
    "\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass education_level  education-num       marital-status  \\\n",
       "0   39          State-gov       Bachelors           13.0        Never-married   \n",
       "1   50   Self-emp-not-inc       Bachelors           13.0   Married-civ-spouse   \n",
       "2   38            Private         HS-grad            9.0             Divorced   \n",
       "3   53            Private            11th            7.0   Married-civ-spouse   \n",
       "4   28            Private       Bachelors           13.0   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race      sex  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male        2174.0   \n",
       "1     Exec-managerial         Husband   White     Male           0.0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male           0.0   \n",
       "3   Handlers-cleaners         Husband   Black     Male           0.0   \n",
       "4      Prof-specialty            Wife   Black   Female           0.0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country income  \n",
       "0           0.0            40.0   United-States  <=50K  \n",
       "1           0.0            13.0   United-States  <=50K  \n",
       "2           0.0            40.0   United-States  <=50K  \n",
       "3           0.0            40.0   United-States  <=50K  \n",
       "4           0.0            40.0            Cuba  <=50K  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census = pd.read_csv(filepath)\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "A short investigation of the dataset will determine how many individuals fit into either group, and will tell us about the percentage of these individuals making more than \\$50,000.\n",
    "\n",
    "In the code cell below, you will need to compute the following:\n",
    "- The total number of records, `'n_records'` HINT: You might want to use *df.shape* or pandas method *.value_counts()*\n",
    "- The number of individuals making more than \\$50,000 annually, `'n_greater_50k'`.\n",
    "- The number of individuals making at most \\$50,000 annually, `'n_at_most_50k'`.\n",
    "- The percentage of individuals making more than \\$50,000 annually, `'greater_percent'`.\n",
    "\n",
    "** HINT: ** You may need to look at the table above to understand how the `'income'` entries are formatted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222, 14)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = census\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    34014\n",
       ">50K     11208\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 45222\n",
      "Individuals making more than $50,000: 11208\n",
      "Individuals making at most $50,000: 34014\n",
      "Percentage of individuals making more than $50,000: 24.78439697492371%\n"
     ]
    }
   ],
   "source": [
    "n_records = data.shape[0]\n",
    "n_greater_50k = np.sum(data['income']== '>50K')\n",
    "n_at_most_50k = np.sum(data['income']== '<=50K')\n",
    "greater_percent = n_greater_50k *100/n_records\n",
    "\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50,000: {}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature set exploration:**\n",
    "\n",
    "* **age**: continuous. \n",
    "* **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "* **education_level**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "* **education-num**: continuous. \n",
    "* **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
    "* **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "* **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "* **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. \n",
    "* **gender**: Female, Male. \n",
    "* **capital-gain**: continuous. \n",
    "* **capital-loss**: continuous. \n",
    "* **hours-per-week**: continuous. \n",
    "* **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinidad&Tobago, Peru, Hong, Holland-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Experiment with visualizing the data. Can you find out which features influence the income the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['education-num'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured. This is typically known as **preprocessing**. Fortunately, for this dataset, there are no invalid or missing entries we must deal with. However, there are some qualities about certain features that must be adjusted. This preprocessing can help tremendously with the outcome and predictive power of nearly all learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the target variable from the features.\n",
    "- Store the column  `'income'` in a variable `'income_raw'`\n",
    "- Store the features in a variable `'features_raw'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass education_level  education-num       marital-status  \\\n",
       "0   39          State-gov       Bachelors           13.0        Never-married   \n",
       "1   50   Self-emp-not-inc       Bachelors           13.0   Married-civ-spouse   \n",
       "2   38            Private         HS-grad            9.0             Divorced   \n",
       "3   53            Private            11th            7.0   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race    sex  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White   Male        2174.0   \n",
       "1     Exec-managerial         Husband   White   Male           0.0   \n",
       "2   Handlers-cleaners   Not-in-family   White   Male           0.0   \n",
       "3   Handlers-cleaners         Husband   Black   Male           0.0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country  \n",
       "0           0.0            40.0   United-States  \n",
       "1           0.0            13.0   United-States  \n",
       "2           0.0            40.0   United-States  \n",
       "3           0.0            40.0   United-States  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_raw = data['income']\n",
    "feature_raw = data.drop('income',axis = 1)\n",
    "feature_raw[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transforming Skewed Continuous Features**\n",
    "\n",
    "A dataset may sometimes contain at least one feature whose values tend to lie near a single number, but will also have a non-trivial number of vastly larger or smaller values than that single number.  Algorithms can be sensitive to such distributions of values and can underperform if the range is not properly normalized. With the census dataset two features fit this description: '`capital-gain'` and `'capital-loss'`. \n",
    "\n",
    "Plot a histogram of these two features. Note the range of the values and how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize skewed continuous features of original data\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (8,5)); # Create figure\n",
    " # Skewed feature plotting\n",
    "for i, feature in enumerate(['capital-gain','capital-loss']):\n",
    "    ax = fig.add_subplot(1, 2, i+1) # \n",
    "    ax.hist(data[feature], bins = 25, color = '#00A0A0')\n",
    "    ax.set_title(\"Feature Distribution {}\".format(feature), fontsize = 12)\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Number of Records\")\n",
    "    ax.set_ylim((0, 2000))\n",
    "    ax.set_yticks([0, 500, 1000, 1500, 2000])\n",
    "    ax.set_yticklabels([0, 500, 1000, 1500, \">2000\"])\n",
    "\n",
    "fig.suptitle(\"Skewed Distributions of Continuous Census Data Features\", \\\n",
    "            fontsize = 14, y = 1.05)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For highly-skewed feature distributions such as `'capital-gain'` and `'capital-loss'`, it is common practice to apply a **logarithmic transformation** on the data so that the very large and very small values do not negatively affect the performance of a learning algorithm. Using a logarithmic transformation significantly **reduces the range of values caused by extreme values**.\n",
    "\n",
    "Care must be taken when applying this transformation however: The logarithm of `0` is undefined, so we must translate the values by a small amount above `0` to apply the the logarithm successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = feature_raw)\n",
    "features_log_transformed[skewed] = feature_raw[skewed].apply(lambda x: np.log(x+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the new log distributions\n",
    "\n",
    "fig = plt.figure(figsize = (8,5)); # Create figure\n",
    " # Skewed feature plotting\n",
    "for i, feature in enumerate(['capital-gain','capital-loss']):\n",
    "    ax = fig.add_subplot(1, 2, i+1) # \n",
    "    ax.hist(features_log_transformed[feature], bins = 25, color = '#00A0A0')\n",
    "    ax.set_title(\"Feature Distribution {}\".format(feature), fontsize = 12)\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Number of Records\")\n",
    "    ax.set_ylim((0, 2000))\n",
    "    ax.set_yticks([0, 500, 1000, 1500, 2000])\n",
    "    ax.set_yticklabels([0, 500, 1000, 1500, \">2000\"])\n",
    "    fig.suptitle(\"Log-transformed Distributions of Continuous Census Data Features\", \\\n",
    "            fontsize = 16, y = 1.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing Numerical Features**\n",
    "\n",
    "In addition to performing transformations on features that are highly skewed, it is often good practice to perform some type of *scaling on numerical features*. Applying a scaling to the data does not change the shape of each feature's distribution (such as `'capital-gain'` or `'capital-loss'` above); however, normalization *ensures that each feature is treated equally* when applying supervised learners. Note that once scaling is applied, observing the data in its raw form will no longer have the same original meaning, as the example given below shows.\n",
    "\n",
    "To normalize each numerical feature we will use [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass education_level  education-num  \\\n",
       "0  0.301370          State-gov       Bachelors       0.800000   \n",
       "1  0.452055   Self-emp-not-inc       Bachelors       0.800000   \n",
       "2  0.287671            Private         HS-grad       0.533333   \n",
       "\n",
       "        marital-status          occupation    relationship    race    sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White   Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White   Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0      0.667492           0.0        0.397959   United-States  \n",
       "1      0.000000           0.0        0.122449   United-States  \n",
       "2      0.000000           0.0        0.397959   United-States  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "# store the names of the numerical features in a list\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss','hours-per-week']\n",
    "features_log_minmax_transform = features_log_transformed\n",
    "# apply scaling on numerical features by using the 'fit-transform' method of the scalar object\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "# Show an example of a record with scaling applied\n",
    "features_log_minmax_transform.head(n=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding categorical variables**\n",
    "\n",
    "From the table in above, we can see there are several features for each record that are non-numeric. Typically, learning algorithms expect input to be numeric, which requires that non-numeric features (called *categorical variables*) be converted. One popular way to convert categorical variables is by using the **one-hot encoding** scheme. One-hot encoding creates a _\"dummy\"_ variable for each possible category of each non-numeric feature. For example, assume `someFeature` has three possible entries: `A`, `B`, or `C`. We then encode this feature into `someFeature_A`, `someFeature_B` and `someFeature_C`.\n",
    "\n",
    "|   | someFeature |                    | someFeature_A | someFeature_B | someFeature_C |\n",
    "| :-: | :-: |                            | :-: | :-: | :-: |\n",
    "| 0 |  B  |  | 0 | 1 | 0 |\n",
    "| 1 |  C  | ----> one-hot encode ----> | 0 | 0 | 1 |\n",
    "| 2 |  A  |  | 1 | 0 | 0 |\n",
    "\n",
    "Additionally, as with the non-numeric features, we need to convert the non-numeric target label, `'income'` to numerical values for the learning algorithm to work. Since there are only two possible categories for this label (\"<=50K\" and \">50K\"), we can avoid using one-hot encoding and simply encode these two categories as `0` and `1`, respectively.\n",
    "\n",
    "In code cell below, you will need to implement the following:\n",
    " - Use [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) to perform one-hot encoding on the `'features_log_minmax_transform'` data.\n",
    " - Convert the target label `'income_raw'` to numerical entries.\n",
    "   - Set records with \"<=50K\" to `0` and records with \">50K\" to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "# Encode the 'income_raw' data to numerical values\n",
    "income = income_raw.apply(lambda x: 0 if x == '<=50K' else 1)\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "#print(encoded)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle and Split Data**\n",
    "\n",
    "Now all _categorical variables_ have been converted into numerical features, and all numerical features have been normalized. As always, we will now split the data (both features and their labels) into training and test sets. 80% of the data will be used for training and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 36177 samples.\n",
      "Testing set has 9045 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, income,test_size = 0.2)\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics and the Naive Predictor**\n",
    "\n",
    "It might seem that using **accuracy** as a metric for evaluating a particular model's performance would be appropriate.\n",
    "\n",
    "In this exercise, we are particularly interested in predicting who makes more than \\$50,000 accurately.\n",
    "\n",
    "Therefore, a model's ability to precisely predict those that make more than \\$50,000 is *more important* than the model's ability to **recall** those individuals. We can use **F-1 score** as a metric that considers both precision and recall:\n",
    "\n",
    "$$ F_{1} = 2 \\cdot \\frac{precision \\cdot recall}{precision  + recall} $$\n",
    "\n",
    "Looking at the distribution of classes (those who make at most \\$50,000, and those who make more), it's clear most individuals do not make more than \\$50,000. This can greatly affect **accuracy**, since we could simply say *\"this person does not make more than \\$50,000\"* and generally be right, without ever looking at the data! Making such a statement would be called **naive**, since we have not considered any information to substantiate the claim. It is always important to consider the *naive prediction* for your data, to help establish a benchmark for whether a model is performing well. That been said, using that prediction would be pointless: If we predicted all people made less than \\$50,000, would identify no one as earning more. \n",
    "\n",
    "**Note: Recap of accuracy, precision, recall**\n",
    "\n",
    "**Accuracy** measures how often the classifier makes the correct prediction. It is the ratio of the number of correct predictions to the total number of predictions (the number of test data points).\n",
    "\n",
    "**Precision** tells us what proportion, e.g., of messages we classified as spam, actually were spam.\n",
    "It is a ratio of true positives (words classified as spam, and which are actually spam) to all positives (all words classified as spam, irrespective of whether that was the correct classification), in other words it is the ratio of\n",
    "\n",
    "`[True Positives/(True Positives + False Positives)]`\n",
    "\n",
    "**Recall(sensitivity)** tells us what proportion of messages that actually were spam were classified by us as spam.\n",
    "It is a ratio of true positives (words classified as spam, and which are actually spam) to all the words that were actually spam, in other words it is the ratio of\n",
    "\n",
    "`[True Positives/(True Positives + False Negatives)]`\n",
    "\n",
    "For classification problems that are skewed in their classification distributions like in our case, for example, if we had a 100 text messages and only 2 were spam and the rest (98) weren't, accuracy by itself is not a very good metric. We could classify 90 messages as not spam(including the 2 that were spam but we classify them as not spam, hence they would be false negatives) and 10 as spam(all 10 false positives) and still get a reasonably good accuracy score. For such cases, precision and recall come in very handy. These two metrics can be combined to get the F1 score, which is weighted average (harmonic mean) of the precision and recall scores. This score can range from 0 to 1, with 1 being the best possible F1 score (we take the harmonic mean as we are dealing with ratios)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Predictor Performance**\n",
    "\n",
    "* If we chose a model that always predicted an individual made more than $50,000, what would  that model's accuracy and F1-score be on this dataset? You must use the code cell below and assign your results to `'accuracy'` and `'fscore'` to be used later.\n",
    "\n",
    "**Please note** that the the purpose of generating a naive predictor is simply to show what a base model without any intelligence would look like. In the real world, ideally your base model would be either the results of a previous model or could be based on a research paper upon which you are looking to improve. When there is no benchmark model set, getting a result better than random choice is a place you could start from.\n",
    "\n",
    "**HINT:** \n",
    "\n",
    "* When we have a model that always predicts '1' (i.e. the individual makes more than 50k) then our model will have no True Negatives(TN) or False Negatives(FN) as we are not making any negative('0' value) predictions. Therefore our Accuracy in this case becomes the same as our Precision (True Positives/(True Positives + False Positives)) as every prediction that we have made with value '1' that should have '0' becomes a False Positive; therefore our denominator in this case is the total number of records we have in total. \n",
    "* Our Recall score(True Positives/(True Positives + False Negatives)) in this setting becomes 1 as we have no False Negatives.\n",
    "\n",
    "**Calculate accuracy, precision, recall, and f1-score yourself.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = np.sum(income)\n",
    "FP = income.count() - TP\n",
    "TN = 0 # No predicted negatives in the naive case\n",
    "FN = 0 # No predicted negatives in the naive case\n",
    "\n",
    "# Calculate accuracy, precision and recall yourself\n",
    "accuracy = 0.0 # <- your code here\n",
    "recall = 0.0 # <- your code here\n",
    "precision = 0.0 # <- your code here\n",
    "\n",
    "# Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
    "fscore = 0.0 # <- your code here\n",
    "# Print the results\n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Predicting Pipeline\n",
    "\n",
    "In the code cell below, you will need to implement the following:\n",
    " - Import `LogisticRegression` and  [`sklearn.linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model).\n",
    " - Import confusion_matrix and classification_report from sklearn.metrics.\n",
    " - Import `fbeta_score` and `accuracy_score` from [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    " - Instantiate a logistic regression object (learner) \n",
    "   - be aware about the C parameter - regularization stength - experiment with different values for this parameter (check also the part about cross validation further below)\n",
    " - Fit the learner to the training data\n",
    " - Perform predictions on the test data `X_test`. \n",
    " - Calculate the accuracy score for both the training subset and testing set.\n",
    " - Compute and print the confusion matrix and classification report. HINT: both take as parameters (y_test, y_pred)\n",
    " - Calculate the F-score for both the training subset and testing set.\n",
    "   - Make sure that you set the `beta` parameter 'beta' = 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6242  534]\n",
      " [ 902 1367]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      6776\n",
      "           1       0.72      0.60      0.66      2269\n",
      "\n",
      "    accuracy                           0.84      9045\n",
      "   macro avg       0.80      0.76      0.78      9045\n",
      "weighted avg       0.83      0.84      0.84      9045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting an ROC curve**\n",
    "\n",
    "Classification reports and confusion matrices are methods to quantitatively evaluate model performance, while receiver operating characteristic curves (ROC) provide a way to visually evaluate models. Most classifiers in scikit-learn have a *.predict_proba()* method which returns the probability of a given sample being in a particular class. Having built a logistic regression model, you'll now evaluate its performance by plotting an ROC curve. In doing so, you'll make use of the .predict_proba() method and become familiar with its functionality.\n",
    "\n",
    "* Import roc_curve from sklearn.metrics.\n",
    "* Using the logreg classifier, which has been fit to the training data, compute the predicted probabilities of the labels of the test set X_test. Save the result as y_pred_prob.\n",
    "* Use the roc_curve() function with y_test and y_pred_prob and unpack the result into the variables fpr, tpr, and thresholds.\n",
    "* Plot the ROC curve with fpr on the x-axis and tpr on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = log_reg.predict_proba(X_test)[:,1]\n",
    "# Generate ROC curve values: fpr, tpr, thresholds HINT: roc_curve takes as arguments (y_test, y_pred_prob)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Similar to the alpha parameter of lasso and ridge regularization that you saw for linear regression, logistic regression also has a regularization parameter: C, which controls the inverse of the regularization strength. \n",
    "\n",
    "A large C can lead to an overfit model, while a small C can lead to an underfit model. Practice with different values for C parameter and evaluate the trained models. Which is the optimal value for C?\n",
    "\n",
    "In addition to C, logistic regression has a 'penalty' hyperparameter which specifies whether to use 'l1' or 'l2' regularization. Experiment with the different type of regularization methods!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Validation in scikit-learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is a statistical method of evaluating generalization performance\n",
    "- more stable than train test split\n",
    "- the data is split repeatedly (equal parts called 'folds') and multiple models are trained\n",
    "\n",
    "*Important* - cross validation does not return a model! It cannot be applied to new data!\n",
    "But: multiple models are built internally, its purpose is to evaluate how well a given algorithms (with a set of hyperparameters) will generalize when trained on a specific dataset!\n",
    "\n",
    "* import cross_val_score from model_selection submodule\n",
    "* instantiate a Logistic Regression object (estimator) with default parameters (use max_iter=1000)\n",
    "* call cross_val_score by providing the estimator, features and labels as arguments\n",
    "\n",
    "**This might take a little time!** Fortunately, you can use several parallel jobs (with the parameter n_jobs) for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.84355998 0.84618574 0.83745681 0.84616448 0.83842433]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "log_reg_obj = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(log_reg_obj, X_train, y_train, n_jobs=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by looking at the output of the cross_val_score, which is the default number of folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.84\n"
     ]
    }
   ],
   "source": [
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **cross_validate()** gives more informative outcomes: Evaluation metric(s) by cross-validation and also record fit/score times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.08654881, 4.08845162, 4.24089217, 3.99167156, 4.1746242 ]),\n",
       " 'score_time': array([0.00286937, 0.00301909, 0.00298047, 0.00282764, 0.00283456]),\n",
       " 'test_score': array([0.84355998, 0.84618574, 0.83745681, 0.84616448, 0.83842433])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(log_reg_obj, X_train, y_train, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross-Validation and others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More control over cross-validation\n",
    "\n",
    "* cross_validate allows us to adjust the number of folds that are used using the **cv = ** parameter\n",
    "* a finer control over the splitting process is possible by providing a cross-validation **splitter** object as parameter to a **cross validation object***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks:**\n",
    "* create a Kfold object by specifing the parameter *n_splits=5*)\n",
    "* use the kfold object as value for the *cv =* parameters for a *cross_val_score* object along with your classifier and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.84328358 0.84784411 0.83718037 0.84602626 0.83676572]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "scores = cross_val_score(log_reg_obj, X_train, y_train, cv=kfold, n_jobs=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle-split cross-validation**\n",
    "\n",
    "This strategy allows to split *n_split* times, each split **sampling (with replacement)**\n",
    "- *train_size* many points from the dataset and\n",
    "- *test_size* many data points for the test set\n",
    "\n",
    "**Tasks:**\n",
    "* instantiate a ShuffleSplit object by specifying as values for the parameters: *test_size= .5, train_size= 0.5, n_splits= 10*\n",
    "* use the  ShuffleSplit object as value for the *cv =* parameters for a *cross_val_score* object along with your classifier and data\n",
    "\n",
    "(It is also sufficient to only provide train_size or test_size, as the other value is then determined by the ShuffleSplit class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.84122948 0.83885234 0.83863121 0.84216927 0.8423904  0.84471226\n",
      " 0.84189286 0.84205871 0.83995799 0.84056609]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle_split = ShuffleSplit(n_splits=10, test_size=0.5, train_size=0.5)\n",
    "scores = cross_val_score(log_reg_obj, X_train, y_train, cv=shuffle_split,n_jobs=10)\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "* goal is to improve the generalization of the model by  tuning the hyperparameters\n",
    "* it is important to understand what the hyperparameters mean before tuning them\n",
    "* grid search: trying given combinations to find the best model according to some validation metric\n",
    "\n",
    "The following is a naive grid search implementation.\n",
    "\n",
    "**This will take a while, since the logistic regression classifier is trained in sequence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 36177 size of test set: 9045\n",
      "Found better model with C=0.01 that gives a score of 0.838253178551686\n",
      "Found better model with C=0.1 that gives a score of 0.840685461580984\n",
      "Best score: 0.84\n",
      "Best parameter: {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, income,test_size=0.2)\n",
    "print(\"Size of training set: {} size of test set: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "best_score = 0\n",
    "for C in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "# for each combination of parameters, train a LogReg model\n",
    "    log_reg = LogisticRegression(C=C, max_iter=1000)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "# evaluate the LogReg on the test set\n",
    "    score = log_reg.score(X_test, y_test)\n",
    "# if we got a better score, store the score and parameters\n",
    "    if score > best_score:\n",
    "        print(f'Found better model with C={C} that gives a score of {score}')\n",
    "        best_score = score\n",
    "        best_parameters = {'C': C}\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameter: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning with GridSearchCV**\n",
    "\n",
    "\n",
    "Like the alpha parameter of lasso and ridge regularization that you saw earlier, logistic regression also has a regularization parameter: C. C controls the inverse of the regularization strength. A **large `C`** can lead to an **overfit** model, while a small C can lead to an underfit model. The hyperparameter space for C has been setup for you in the variable c_space.\n",
    "\n",
    "* Your task is to use GridSearchCV and logistic regression to find the optimal C in this hyperparameter space. The feature array is available as `'features_final'` and target variable array is available as `'income'`.\n",
    "* You may be wondering why you aren't asked to split the data into training and test sets. Here, we want you to focus on the process of **setting up the hyperparameter grid and performing grid-search cross-validation**. In practice, you will indeed want to hold out a portion of your data for evaluation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks:**\n",
    "\n",
    "* Import LogisticRegression from sklearn.linear_model and GridSearchCV from sklearn.model_selection.\n",
    "* Setup the hyperparameter grid by using `c_space` as the grid of values to tune C over.\n",
    "* Instantiate a logistic regression classifier called `logreg`.\n",
    "* Use GridSearchCV to instantiate an object `logreg_cv` with 5-fold cross-validation to tune `C`:\n",
    "* Inside GridSearchCV(), specify:  **a classifier, parameter grid, and number of folds to use.**\n",
    "* Use the `.fit()` method on the GridSearchCV object to fit it to the`'features_final'` data and target `'income'`.\n",
    "* Print the best parameter and best score obtained from GridSearchCV by accessing the `best_params_` and `best_score_` attributes of `logreg_cv`.\n",
    "\n",
    "**This might actually take a little while.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 0.4393970560760795}\n",
      "Best score is 0.8414931583177043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5, n_jobs=15)\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(features_final, income)\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct and train a decision tree with a maximum depth of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400221116639027"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct and train a decision tree with a maximum depth of 3. Compare the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442233278054173"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct and train a decision tree with a maximum number of leaf nodes using the parameter *max_leaf_nodes=8*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442233278054173"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_leaf_nodes=6)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct and train a decision tree with a minimum required number samples for a split *min_samples_split=50*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8509673852957435"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(min_samples_split=50)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last, with min_impurity_decrease of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400221116639027"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit DT with min_impurity_decrease=.01\n",
    "tree = DecisionTreeClassifier(min_impurity_decrease=0.01)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks:**\n",
    "* import GridSearchCV from sklearn.model_selection\n",
    "* create and fit a  GridSearchCV object using as parametres: DecisionTreeClassifier object, param_grid, cv = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=10,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(1, 10)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=10,\n",
       "             param_grid={&#x27;max_depth&#x27;: range(1, 10)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=10,\n",
       "             param_grid={'max_depth': range(1, 10)})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth':range(1, 10)}\n",
    "tree = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(tree, param_grid, cv=10, n_jobs=10)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194498</td>\n",
       "      <td>0.043686</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>0.752349</td>\n",
       "      <td>0.752349</td>\n",
       "      <td>0.752349</td>\n",
       "      <td>0.752073</td>\n",
       "      <td>0.752073</td>\n",
       "      <td>0.752073</td>\n",
       "      <td>0.752073</td>\n",
       "      <td>0.752281</td>\n",
       "      <td>0.752281</td>\n",
       "      <td>0.752281</td>\n",
       "      <td>0.752218</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242057</td>\n",
       "      <td>0.062560</td>\n",
       "      <td>0.018604</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.829464</td>\n",
       "      <td>0.823936</td>\n",
       "      <td>0.822554</td>\n",
       "      <td>0.828082</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.831951</td>\n",
       "      <td>0.823107</td>\n",
       "      <td>0.818911</td>\n",
       "      <td>0.830523</td>\n",
       "      <td>0.818911</td>\n",
       "      <td>0.824225</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.329093</td>\n",
       "      <td>0.060232</td>\n",
       "      <td>0.010825</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>0.843836</td>\n",
       "      <td>0.840243</td>\n",
       "      <td>0.838308</td>\n",
       "      <td>0.842731</td>\n",
       "      <td>0.831675</td>\n",
       "      <td>0.847706</td>\n",
       "      <td>0.838861</td>\n",
       "      <td>0.836605</td>\n",
       "      <td>0.846558</td>\n",
       "      <td>0.832181</td>\n",
       "      <td>0.839871</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.194498      0.043686         0.002913        0.000254   \n",
       "1       0.242057      0.062560         0.018604        0.032070   \n",
       "2       0.329093      0.060232         0.010825        0.025006   \n",
       "\n",
       "  param_max_depth            params  split0_test_score  split1_test_score  \\\n",
       "0               1  {'max_depth': 1}           0.752349           0.752349   \n",
       "1               2  {'max_depth': 2}           0.829464           0.823936   \n",
       "2               3  {'max_depth': 3}           0.843836           0.840243   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0           0.752349           0.752073           0.752073           0.752073   \n",
       "1           0.822554           0.828082           0.814815           0.831951   \n",
       "2           0.838308           0.842731           0.831675           0.847706   \n",
       "\n",
       "   split6_test_score  split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0           0.752073           0.752281           0.752281           0.752281   \n",
       "1           0.823107           0.818911           0.830523           0.818911   \n",
       "2           0.838861           0.836605           0.846558           0.832181   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.752218        0.000122                9  \n",
       "1         0.824225        0.005393                8  \n",
       "2         0.839871        0.005202                7  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(grid.cv_results_)\n",
    "scores[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with RandomizedSearchCV\n",
    "\n",
    "GridSearchCV can be computationally expensive, especially when searching multiple hyperparameters over a large hyperparameter space. A solution to this is to use **RandomizedSearchCV**, in which not all hyperparameter values are tried out. Instead, a **fixed number of hyperparameter settings is sampled from specified probability distributions**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you'll apply the classifier of a Decision Tree. Just like linear regression, and logistic regression, decision trees in scikit-learn have `.fit()` and `.predict()` methods that you can use in exactly the same way as before.\n",
    "\n",
    "Decision trees have many parameters that can be tuned, such as max_features, max_depth, and min_samples_leaf: This makes it an ideal use case for RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature array is available as `'features_final'` and target variable array is available as `'income'`. The hyperparameter settings have been specified for you. Your goal is to use RandomizedSearchCV to find the optimal hyperparameters.\n",
    "\n",
    "\n",
    "* Import DecisionTreeClassifier from sklearn.tree and RandomizedSearchCV from sklearn.model_selection.\n",
    "* Specify the parameters and distributions to sample from. This has been done for you.\n",
    "* Instantiate a DecisionTreeClassifier.\n",
    "* Use RandomizedSearchCV with 5-fold cross-validation to tune the hyperparameters:\n",
    "* Inside RandomizedSearchCV(), specify the classifier, parameter distribution, and number of folds to use.\n",
    "* Use the .fit() method on the RandomizedSearchCV object to fit it to the data  and target.\n",
    "* Print the best parameter and best score obtained from RandomizedSearchCV by accessing the best_params_ and best_score_ attributes of tree_cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': 6, 'min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Decision Tree classifier: \n",
    "tree = DecisionTreeClassifier()\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5, n_jobs=5)\n",
    "# Fit it to the data\n",
    "tree_cv.fit(features_final, income)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task: Classification\n",
    "\n",
    "You will now practice evaluating a model with tuned hyperparameters \n",
    "In addition to C, logistic regression has a 'penalty' hyperparameter which specifies whether to use 'l1' or 'l2' regularization. Your job in this exercise is to create a hold-out set, tune the 'C' and 'penalty' hyperparameters of a logistic regression classifier using GridSearchCV on the training set, and then evaluate its performance against the hold-out set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the hyperparameter grid (a dictionary where the keys correspond to the names of the hyperparameters to be tuned, and the values are lists containing the values to be tried:\n",
    "    * Use the provided array **c_space** as the grid of values for 'C'.\n",
    "    * For 'penalty', specify a list consisting of 'l1' and 'l2'.\n",
    "* Instantiate a logistic regression classifier.\n",
    "* Create training and test sets. Use a test_size of 0.4 and random_state of 42. In practice, the test set here will function as the hold-out set.\n",
    "* Tune the hyperparameters on the training set using GridSearchCV with 5-folds. This involves first instantiating the * * GridSearchCV object with the correct parameters (estimator, grid parameters, number of folds) and then fitting it to the training data.\n",
    "* Print the best parameter and best score obtained from GridSearchCV by accessing the `best_params_` and `best_score_` attributes of logreg_cv.\n",
    "* Evaluate these optimal values on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = None\n",
    "# Fit it to the training data\n",
    "# one line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the scores and print parameters with **logreg_cv.best_score_** and **logreg_cv.best_params_**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
